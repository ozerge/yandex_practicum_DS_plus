# Выявление негативных комментариев с BERT

Раздел курса | Цель | Вывод| Ключевые слова проекта | Используемые библиотеки
------------- |----------------| ---------------- | ---------------- | -----------------------
Машинное обучение для текстов |Задача — на основе набора данных с разметкой о токсичности правок обучить модель классифицировать комментарии на позитивные и негативные. По условию значение метрики качества F1 должно быть не меньше 0.75. | Провел предобработку и анализ данных. Задача была выполнена с помощью предобученной модели BERT(toxic-bert). Рекомендовал модель Logistic Regression, со значением F1-меры в 0.95, что превышает заданное значение в 0.75. Полные выводы исследования см. проект|  обработка естественного языка, NLP | `Python`, `Pandas`, `Numpy`, `Seaborn`, `Matplotlib`, `Scikit-learn`, `CatBoost`, `LightGBM`, `BERT`, `nltk`  


